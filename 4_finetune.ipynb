{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such device (os error 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m M_CONFIG \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AbsTokenizer()\n\u001b[0;32m---> 15\u001b[0m model_state \u001b[38;5;241m=\u001b[39m \u001b[43m_load_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model_state \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m model_state\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotary_emb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k}\n",
      "File \u001b[0;32m~/maikyon/miniconda3/envs/p2q-transformer/lib/python3.11/site-packages/aria/utils.py:72\u001b[0m, in \u001b[0;36m_load_weight\u001b[0;34m(ckpt_path, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install safetensors in order to read from the checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/maikyon/miniconda3/envs/p2q-transformer/lib/python3.11/site-packages/safetensors/torch.py:311\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mLoads a safetensors file into torch format.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    313\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget_tensor(k)\n",
      "\u001b[0;31mOSError\u001b[0m: No such device (os error 19)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "from aria.model import TransformerLM, ModelConfig\n",
    "from aria.utils import _load_weight\n",
    "from aria.config import load_model_config\n",
    "from aria.tokenizer import AbsTokenizer, SeparatedAbsTokenizer\n",
    "\n",
    "from torch.nn import Embedding, Linear\n",
    "\n",
    "M_PATH = \"piano-medium-stacked-1.0.safetensors\"\n",
    "M_CONFIG = \"medium\"\n",
    "\n",
    "tokenizer = AbsTokenizer()\n",
    "model_state = _load_weight(M_PATH, device=\"cpu\")\n",
    "model_state = {k: v for k, v in model_state.items() if \"rotary_emb\" not in k}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = ModelConfig(**load_model_config(M_CONFIG))\n",
    "model_config.set_vocab_size(tokenizer.vocab_size)\n",
    "model = TransformerLM(model_config).to(\"cpu\")\n",
    "model.load_state_dict(model_state)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    _embedding = Embedding(\n",
    "        num_embeddings=_tokenizer.vocab_size,\n",
    "        embedding_dim=model_config.d_model,\n",
    "    )\n",
    "    _embedding.weight[: -(_tokenizer.vocab_size - tokenizer.vocab_size)] = (\n",
    "        model.model.tok_embeddings.weight\n",
    "    )\n",
    "\n",
    "    _lm_head = Linear(model_config.d_model, _tokenizer.vocab_size, bias=False)\n",
    "    _lm_head.weight[: -(_tokenizer.vocab_size - tokenizer.vocab_size)] = (\n",
    "        model.lm_head.weight\n",
    "    )\n",
    "\n",
    "    model.model.tok_embeddings = _embedding\n",
    "    model.lm_head = _lm_head\n",
    "\n",
    "# Remove rotary embedding stuff\n",
    "state_dict = model.state_dict()\n",
    "state_dict = {k: v for k, v in state_dict.items() if \"rotary_emb\" not in k}\n",
    "\n",
    "save_file(\n",
    "    state_dict,\n",
    "    \"/home/loubb/work/aria/models/medium-stretched.safetensors\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Stretched input/output layers from {tokenizer.vocab_size} to {_tokenizer.vocab_size} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mamt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AmtEncoderDecoder\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m AmtEncoderDecoder(\u001b[43mmodel_config\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_config' is not defined"
     ]
    }
   ],
   "source": [
    "from amt.model import AmtEncoderDecoder\n",
    "\n",
    "\n",
    "model = AmtEncoderDecoder(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
