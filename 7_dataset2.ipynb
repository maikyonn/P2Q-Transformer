{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amt.config import load_model_config\n",
    "from amt.model import AmtEncoderDecoder, ModelConfig\n",
    "from aria.tokenizer import AbsTokenizer\n",
    "import torch\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "from amt.model import ModelConfig\n",
    "from aria.utils import _load_weight\n",
    "from amt.config import load_model_config\n",
    "from aria.tokenizer import SeparatedAbsTokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from aria.data.midi import MidiDict\n",
    "from aria.tokenizer import AbsTokenizer\n",
    "\n",
    "from src.config import get_config\n",
    "from src.model import P2QTransformer\n",
    "import os\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from progress.bar import Bar  # Assuming you're using the progress package for the progress bar\n",
    "from src.dataset import get_ds\n",
    "\n",
    "from src.load_aria_weights import get_p2q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/ubuntu/maikyon/miniconda3/envs/p2q-transformer/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/ubuntu/maikyon/miniconda3/envs/p2q-transformer/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest Song Length:  1024\n",
      "Number of data points in training set:  1294\n",
      "Number of data points in validation set:  135\n",
      "Training with batch size:  16\n",
      "Steps per epoch:  80\n"
     ]
    }
   ],
   "source": [
    "config = get_config()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AbsTokenizer()\n",
    "train_dataloader, val_dataloader, vocab_size, tokenizer = get_ds(config, train_size_limit=160, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all slightly messy as train_loop and val_loop make use of the\n",
    "# variables in the wider scope. Perhaps refactor this at some point.\n",
    "\n",
    "def train_loop(dataloader, _epoch: int):\n",
    "    loss_buffer = []\n",
    "    model.train()\n",
    "    for step, batch in (\n",
    "        pbar := tqdm(\n",
    "            enumerate(dataloader),\n",
    "            total=len(dataloader),\n",
    "            leave=False,\n",
    "        )\n",
    "    ):\n",
    "        enc_input, src, tgt, idxs = batch\n",
    "        enc_input = enc_input.to(device)\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        logits = model(enc_input, src)  # (b_sz, s_len, v_sz)\n",
    "        logits = logits.transpose(1, 2)  # Transpose for CrossEntropyLoss\n",
    "        loss = loss_fn(logits, tgt)\n",
    "        \n",
    "\n",
    "        writer.add_scalar('train loss', loss.item(), global_step)\n",
    "        writer.flush()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        loss_buffer.append(loss)\n",
    "        avg_val_loss = sum(loss_buffer) / len(loss_buffer)\n",
    "        pbar.set_postfix_str(f\"average_loss={round(avg_val_loss.item(), 4)}\")\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_loop(dataloader, _epoch: int):\n",
    "    loss_buffer = []\n",
    "    model.eval()\n",
    "    for step, batch in (\n",
    "        pbar := tqdm(\n",
    "            enumerate(dataloader),\n",
    "            total=len(dataloader),\n",
    "            leave=False,\n",
    "        )\n",
    "    ):\n",
    "        enc_input, src, tgt, idxs = batch\n",
    "        enc_input = enc_input.to(device)\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        logits = model(enc_input, src)  # (b_sz, s_len, v_sz)\n",
    "        logits = logits.transpose(1, 2)  # Transpose for CrossEntropyLoss\n",
    "        loss = loss_fn(logits, tgt)\n",
    "\n",
    "        # Logging\n",
    "        loss_buffer.append(loss)\n",
    "        avg_val_loss = sum(loss_buffer) / len(loss_buffer)\n",
    "        pbar.set_postfix_str(f\"average_loss={round(avg_val_loss.item(), 4)}\")\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m val_loop(val_dataloader, epoch)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     run_validation(model, val_dataloader, tokenizer, 512, device, lambda msg: batch_iterator.write(msg), global_step, writer)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, _epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m     loss_buffer\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     31\u001b[0m     avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_buffer) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loss_buffer)\n\u001b[0;32m---> 32\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[43mavg_val_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_val_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_p2q(tokenizer).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], eps=1e-9)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.encode([('<P>')]), label_smoothing=0.1).to(device)\n",
    "\n",
    "initial_epoch = 0\n",
    "global_step = 0\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(initial_epoch, config['num_epochs']):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "\n",
    "    train_loop(train_dataloader, epoch)\n",
    "    val_loop(val_dataloader, epoch)\n",
    "\n",
    "\n",
    "    # if epoch % 10 == 0:\n",
    "    #     run_validation(model, val_dataloader, tokenizer, 512, device, lambda msg: batch_iterator.write(msg), global_step, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
